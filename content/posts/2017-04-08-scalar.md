+++
draft = true
date = "2017-04-08"
title = "Scalar - confrence notes"
description = "???"
categories = ["scala"]
tags = ["scala", "scalar", "typeclass", "macro"]
+++

# Day 1 - 2016-04-08

## Random

* https://github.com/zalando/tech-radar
* https://fsprojects.github.io/Chessie/a-tale-of-3-nightclubs.html
* `du -cks ~/Dropbox/**/*.pdf | sort -nr | head` - top 10 largest pdfs
* `du -cks * | sort -rn | head`
* https://smallpdf.com/ - reduce the size of your PDF online
* https://spring.io/blog/2017/01/04/introducing-kotlin-support-in-spring-framework-5-0

## Dave Gurnell: Adventures in Meta-Programming

* [davegurnell/checklist: Validation library for Scala.](https://github.com/davegurnell/checklist)
* [davegurnell/unindent: Indent-adjusted multiline string literals for Scala.](https://github.com/davegurnell/unindent)
* [java validation - Google Search](https://www.google.pl/search?q=kotlin+vaidation&oq=kotlin+vaidation&aqs=chrome..69i57j0.2994j0j1&sourceid=chrome&ie=UTF-8#q=java+validation)
* [Using Bean Validation - The Java EE 6 Tutorial](http://docs.oracle.com/javaee/6/tutorial/doc/gircz.html)
* [javax.validation (Java(TM) EE 7 Specification APIs)](https://docs.oracle.com/javaee/7/api/javax/validation/package-summary.html)
* [Bean Validation - Home](http://beanvalidation.org/)
* [milessabin/shapeless: Generic programming for Scala](https://github.com/milessabin/shapeless)
* [beezee/shapeless-validation-examples: Using generics to prove a case class can be validated, and executing validation](https://github.com/beezee/shapeless-validation-examples)
* [Defensive Programming via Validating Decorators](http://www.yegor256.com/2016/01/26/defensive-programming.html)
* [Validating Data with Types | Scholars— Lab](http://scholarslab.org/uncategorized/validating-data-with-types/)
* [CQRS in Haskell: Command validation with Applicative Functors - Jayway](https://blog.jayway.com/2014/02/25/cqrs-in-haskell-command-validation-with-applicative-functors/)

## Andrea Lattuada: Typeclasses — a type system construct

### General notes

* Typeclasses are avaliable in example in Haskell, Rust and Scala
* The best - the more readable solution is avaliable in Haskell
* We should try diffrent languages to take the best
* One language - one year

### Scala

* define instances of typeclass in companion objects
* implementing Typeclass requires a lot of bolierplate

#### simulacrum

[simulacrum](https://github.com/mpilquist/simulacrum): First class syntax support for type classes in Scala

* Robust, consiten object-oriented forwarders
* consisten syntax (`@typeclass`)

Note: [cats](https://github.com/typelevel/cats) uses [simulacrum](https://github.com/mpilquist/simulacrum)

## John A. De Goes: Quark: A Purely-Functional Scala DSL for Data Processing & Analytics

How to DSL - Finally Tagless

* [Quasar](https://github.com/quasar-analytics/quasar): Quasar Analytics is a general-purpose compiler for translating data processing and analytics over semi-structured data into efficient plans that run 100% in the target infrastructure.
* [Quark](https://github.com/quasar-analytics/quark): An Embedded DSL for Quasar Analytics

* [Apache Spark](http://spark.apache.org/): is a fast and general engine for large-scale data processing.
* [Hadoop Has Failed Us, Tech Experts Say](https://www.datanami.com/2017/03/13/hadoop-failed-us-tech-experts-say/)

## Gabriele Petronella: Practical Monad Transformers

* Functor - `future.map` - `Functor[Future].map(future)(f)`
* `cats` vs `scalaz` - cats :)
* [Monads do not compose](http://blog.tmorris.net/posts/monads-do-not-compose/)
* `OptionT[F[_], T]`, `EitherT[F[_], A, B]`
* Monad transformet: `F[G[X]` becomes `GT[F[_], X]`
* Free mondas - sperates sturucture and interperetation and effect are separated from program definition - https://github.com/ekmett/free, https://softwaremill.com/free-monads/

## Jan Pustelnik: Conscious consistency with Akka Cluster, CRDTs and Distributed Data

In distributed computing, a conflict-free replicated data type (abbreviated CRDT) is a type of specially-designed data structure used to achieve strong eventual consistency (SEC) and monotonicity (absence of rollbacks).

Distribiuted data structures in Akka

* GSet - grow-only Set
* GCounter - grow-only counter
* PNCounter - Positive-Negative Counter

## Heiko Seeberger: Learn you Akka Streams for great Good!

### Hello, World!

```scala
implicit val system = ActorStstem()
implicit val mat = ActorMaterializer()

Source.single("Hello, World!").to(Sink.foreach(println)).run()
```

### Wait for end

```scala
// ...
import system.dispatcher
// ...

Source.single("Foo")
.toMat(Sink.foreach(println))(Keep.right) // Change
.run()
.onComplete(_ -> system.terminate())
```

### Others sources

```scala
Source.maybe
Source.queue
Source.repeat
```

### Examples

#### Example 1

```scala
Source
  .repeat("Foo")
  .take(7)
  //.zipWithIndex()
  .zip(Source.fromIterator(() => Iterator.fom(0))
  .map {
    case (s, n) =>
      val indent = " " * n
      f"$i$s"
  }
  .toMat(Sink.foreach(println))(Keep.right)
  .run()
  .onComplete(_ -> system.terminate())
```

#### Example 2

```scala
Source
  .repeat("Foo")
  .take(7)
  .zipWithIndex()
  .mapConcat { // mapConcat expects sequence and string is sequecne, so string is changed to Seq[Char]
    case (s, n) =>
      val indent = " " * n
      f"$i$s%n"
  }
  .toMat(Sink.foreach(print))(Keep.right)
  .run()
  .onComplete(_ -> system.terminate())
```

#### Example 3

```scala
Source
  .repeat("Foo")
  .take(7)
  .zipWithIndex()
  .mapConcat { // mapConcat expects sequence and string is sequecne, so string is changed to Seq[Char]
    case (s, n) =>
      val indent = " " * n
      f"$i$s%n"
  }
  .throttle(42, 1.second, 1, ThrottleMode.shaping)
  .toMat(Sink.foreach(print))(Keep.right)
  .run()
  .onComplete(_ -> system.terminate())
```

### Composition

```scala
val sevenLines =
  Source
    .repeat("Foo")
    .take(7)

val toIndentChars =
  Flow[String]
    .zipWithIndex()
    .mapConcat { // mapConcat expects sequence and string is sequecne, so string is changed to Seq[Char]
      case (s, n) =>
        val indent = " " * n
        f"$i$s%n"
    }

val printThrorrled =
  Flow[Char]
  .throttle(42, 1.second, 1, ThrottleMode.shaping)
  .toMat(Sink.foreach(print))(Keep.right)

sevenLines
  .via(toIndentChars)
  .toMap(printThrorrled)(Keep.right)
  .run()
  .onComplete(_ -> system.terminate())
```

### Alpakka

[Alpakka](https://github.com/akka/alpakka): Enterprise Integration (Camel :)) Done Right - http://developer.lightbend.com/docs/alpakka/current/

## Niko Will: Akka cluster management and split brain resolution

> one Microservice is no Microservice - they come in systems

* Gossip
  * covergence,
  * failure detector,
  * leader,
  * seed nodes

### Seed Nodes

`Cluster(system).joinSeedNodes(seedNodes)` or config `akka.cluster.seed-nodes`

### Leave

Always try to leave cluster gracefully. It good idea to add shutdown hook.

### CAP theorem

![CAP](https://lh5.googleusercontent.com/c_vcKz-Jo3XmIHutpOtJxBoysMt_Ny_PL-0cB4Czh4FvIbTEpe9lObaA6sTwsdHJdrtMXqOBNCNoRxYQYnIlu9MxuYIMWcl5dgUSCADFAfOXWuyWRgKWFk99Pg)

### State Diagram for the Member States

#### State Diagram for the Member States (akka.cluster.allow-weakly-up-members=off)

![State Diagram for the Member States (akka.cluster.allow-weakly-up-members=off)](http://doc.akka.io/docs/akka/current/_images/member-states.png)

#### State Diagram for the Member States (akka.cluster.allow-weakly-up-members=on)

![State Diagram for the Member States (akka.cluster.allow-weakly-up-members=on)](http://doc.akka.io/docs/akka/current/_images/member-states-weakly-up.png)

### Split brain resolution

When operating an Akka cluster you must consider how to handle network partitions (a.k.a. split brain scenarios) and machine crashes (including JVM and hardware failures). This is crucial for correct behavior if you use Cluster Singleton or Cluster Sharding, especially together with Akka Persistence.

## Raam Rosh Hai: Tracing Akka Streams

* [AspectJ](https://eclipse.org/aspectj/)
* [Kamon](https://github.com/kamon-io/Kamon)

### [Zipkin](http://zipkin.io/)

In akka you need to add `.async`

https://github.com/apache/incubator-htrace

## Piotr Guzik: Real-time anomaly detection made easy

The most important thing before before new project has started, is why are you doing it.

What are the most important assets?

* People
* Data

Dicsovering datasource and data itself

* Datasource - Druid
* OLAP cube dimensions as domains
* Data ahhregated with 15 mins window
* Metric - simple count

OLAP cubes can be avaliable in-real time

ClickStream - http://www.clickstreamr.com/

Best way do create new alhotyhtm is on whiteboard 

F.A.I.L. (started in R) - whey rewiritne

* Only Data Scientist knows R
* No easy way to deploy code
* ...
* Hard to maintain

Note: Take basic statistic

## Maciej Gorywoda: Artificial Neural Networks in Akka

Bees have approximately [one million neurons](http://jonlieffmd.com/blog/the-remarkable-bee-brain-2) in 0.5 mm; humans have 100 billion neurons. And yet bees can learn, and understand abstract concepts, and make complex decisions.

## Andrzej Ludwikowski: Gatling distilled

### Why so hard?

* hardware - CPU, RAM, storage
* software - OS, Virtualization, DBs
* load
* isolation

Use percentile - 50, 75, 95

### Why Gatling

* non-blocking, asynchronous stack (scala, akka, netty)
* DSL
* recorder (just like Selenium)
* math is good - proper implementation of percentile

### Gatling

* `tryMax(10)`
* `assertions`
* `throttle`

### Others

* http://locust.io/ - An open source load testing tool.
* http://flood.io/ - This is the high performance load testing service you’ve been looking for.

## Ionuț G. Stan: Modularity à la ML

# Day 2 - 2017-04-08

## Daniela Sfregola: Random Data Generation with ScalaCheck

* Scalacheck is for *testing*. It is not for populating in example database, bacause scalacheck is biased - it will generate in example very short lists and very long lists. For generating data for database please use other tools
* [Code from presentation](https://github.com/DanielaSfregola/random-data-generator)

## George Leontiev: Case study for a real-world type-level programming

* [Slides](https://github.com/folone/scalar-conf)
* https://github.com/xdotai/play-json-extensions
* Framwork built on top of Finagle
* `implicit val wrties - Json.writes[Track]` - it is not robust
* SoundClound uses Github for storing internal code (https://github.com/soundcloud/api-web)
* They wrote their internal `Json.writes[Track]`, that could work with more 22 fields (legacy code)

### `HList`

* just like a list, but it also has a type of elements
* `val hlist = 1l :: "hello" :: HNil` -> `hlist: Long :: String :: HNil = 1 :: hello :: HNil`

### `Generic`

* Generic generates Representation from case class
* if we have representation we can map between types - we can generat `HList` from `Track` and then we can map `HList` to `Track` or other type that has the same `apply` signature

```scala
case class Track(id: Long, payload: String)
val generic = Generic[Track] // shapeless.Generic[Track]{type Repr = Long :: String :: HNil}
val representation = generic.to(Track(1, "hello")) // res0.Repr = 1 :: hello :: HNil
representation(0) // Long = 1
representation(1) // String = hello
generic.from(hlist) // Track = Track(1L, "hello")
```

### `LabelledGeneric`

*  LabelledGeneric is similar to Generic, but includes information about field names or class names in addition to the raw structure <sup>[ref](https://github.com/milessabin/shapeless/blob/master/core/src/main/scala/shapeless/generic.scala#L161)</sup>.

## Rüdiger Klaehn: Designing data structures for the typelevel ecosystem

### RadixTree - basics

* prefixed tree
* only for custom use case - it is not good for everything
* tree structure used to implement sets and maps

## Tomasz Kogut: Taking your side-effects aside

* Split classes with side effece - to pure and unpure - to code without sideeffects and with sideeffects
* > Sided effects are no bad, Uncontrolled side effects are bad
* Services
  * Databse
  * RPC
  * Console
  * ...

### Caputure external effects

```scala
trait IO { def run: Unit }
def PrintLine(msg: String): IO = new IO { def run = println(msg) }
```

```scala
trait IO { self =>
  // ...
}
```

### IO (read)

```scala
trait IO[A] { self =>
  def run: A
  def map[B](f: A => B): IO[B]) =
  // ...
}

### General

* with this `IO` we try to control side effects

### Trampolining

* trade stack for heap
* build c all tree
* higher cost than a function call
* it is a special cas of free monad
* type `IO[A] = Free[() -> A, A]`

## Paweł Szulc: Getting more Mileage from your Monads with MTL

* Monads Transformers Library
* [Startup Simulator](https://toggl.com/startup-simulator/)
* Good lecture - TODO download the slides

## Kamil Owczarek: Continous Applications with Spark 2.0

### Description

Spark 2.0 comes with a new, powerful feature - Continous Applications. Unifying the broad choice of inputs and data virtualization with streaming, it enables streaming structured and semi-structured data as DataFrames or Datasets. This, along with the recent developmenets in Spark ML and the introduction of GraphFrames, gives us new, exciting possibilities like building on-line and time-windowed machine learning pipelines and running analysis on graphs updated in real-time. During the presentation, I will present the broad possibilities of Continous Applications on an end-to-end example, from obtaining data to running it through a machine learning pipeline.

### Spark

* Highly Distribiuted and Scalable
* low level opt: Tungsten, Kro, Catalyst
* high leve opt: Spark SQL etc.

### Spark Streaming

* data "as it comes"
* microbatches
* unbounded tables and view

### Continous Application

* SQL queries on streams
* source: Avro, Json, Parquet, Kafka

### Spark 2.0

* up to 10x faster than 1.6
* DataFrame = Dateset[Row]
* SparkSession - new enty point replacing all the contexts
* input - in example - kafka, but also s3 with JSON, HDFS, Sockets
* supports - Joins

### Stream transformation

* stdlib:  map, flatMap, filter, drop
* sql: select, where, or.aoache.spark.sql.functions
* aggregations
* typesafe aggregation: org.spark.sql.....type....function

### Checkpointing

* checkpointing can be used to increase reliability
* end-toend exactly-one delivery guarantee (tracablle source, idempotent sink)

### Timewindow aggregations

* event-time = time embedded witin data
* watermarking - storing aggregated streams for some time in case late data arrived

## Daniel Westheide: A new approach to testable Spark applications

### Testing - property based testing

* good fit for testing pure function
* works really well

## Alan Johnson: Building a Real-time Auction Engine Using Event Sourcing

* Nice presentation

## Renato Cavalcanti: Functional Foundation of Event Sourced Application

* CQRS and EventSourcing are related, but you can have CQRS without EventSourcing and EventSourcing without CQRS, but you probablly should use it together
* https://github.com/strongtyped/fun-cqrs

